main = paste("Single K-Means Attempt #2\n WCV: ",
round(km.faithful2$tot.withinss, 4)))
plot(faithful, col = km.faithful3$cluster,
main = paste("Single K-Means Attempt #3\n WCV: ",
round(km.faithful3$tot.withinss, 4)))
plot(faithful, col = km.faithful4$cluster,
main = paste("Single K-Means Attempt #4\n WCV: ",
round(km.faithful4$tot.withinss, 4)))
plot(faithful, col = km.faithful5$cluster,
main = paste("Single K-Means Attempt #5\n WCV: ",
round(km.faithful5$tot.withinss, 4)))
plot(faithful, col = km.faithfulsim$cluster,
main = paste("Best K-Means Attempt out of 100\n WCV: ",
round(km.faithfulsim$tot.withinss, 4)))
###########################################
#####Tools for Hierarchical Clustering#####
###########################################
library(flexclust) #Loading the flexclust library.
km.faithful1 = kmeans(faithful.scale, centers = 2) #Running the K-means procedure
km.faithful2 = kmeans(faithful.scale, centers = 2) #5 different times, but with
km.faithful3 = kmeans(faithful.scale, centers = 3) #only one convergence of the
km.faithful4 = kmeans(faithful.scale, centers = 3) #algorithm each time.
km.faithful5 = kmeans(faithful.scale, centers = 3)
#Running the algorithm 100 different times and recording the solution with the
#lowest total within-cluster variance.
set.seed(0)
km.faithfulsim = kmeans(faithful.scale, centers = 3, nstart = 100)
#Visually & numerically inspecting the results.
par(mfrow = c(2, 3))
plot(faithful, col = km.faithful1$cluster,
main = paste("Single K-Means Attempt #1\n WCV: ",
round(km.faithful1$tot.withinss, 4)))
plot(faithful, col = km.faithful2$cluster,
main = paste("Single K-Means Attempt #2\n WCV: ",
round(km.faithful2$tot.withinss, 4)))
plot(faithful, col = km.faithful3$cluster,
main = paste("Single K-Means Attempt #3\n WCV: ",
round(km.faithful3$tot.withinss, 4)))
plot(faithful, col = km.faithful4$cluster,
main = paste("Single K-Means Attempt #4\n WCV: ",
round(km.faithful4$tot.withinss, 4)))
km.faithful2 = kmeans(faithful.scale, centers = 3) #5 different times, but with
km.faithful3 = kmeans(faithful.scale, centers = 3) #only one convergence of the
km.faithful4 = kmeans(faithful.scale, centers = 3) #algorithm each time.
km.faithful5 = kmeans(faithful.scale, centers = 3)
#Running the algorithm 100 different times and recording the solution with the
#lowest total within-cluster variance.
set.seed(0)
km.faithfulsim = kmeans(faithful.scale, centers = 3, nstart = 100)
#Visually & numerically inspecting the results.
par(mfrow = c(2, 3))
plot(faithful, col = km.faithful1$cluster,
main = paste("Single K-Means Attempt #1\n WCV: ",
round(km.faithful1$tot.withinss, 4)))
plot(faithful, col = km.faithful2$cluster,
main = paste("Single K-Means Attempt #2\n WCV: ",
round(km.faithful2$tot.withinss, 4)))
plot(faithful, col = km.faithful3$cluster,
main = paste("Single K-Means Attempt #3\n WCV: ",
round(km.faithful3$tot.withinss, 4)))
plot(faithful, col = km.faithful4$cluster,
main = paste("Single K-Means Attempt #4\n WCV: ",
round(km.faithful4$tot.withinss, 4)))
plot(faithful, col = km.faithful5$cluster,
main = paste("Single K-Means Attempt #5\n WCV: ",
round(km.faithful5$tot.withinss, 4)))
plot(faithful, col = km.faithfulsim$cluster,
main = paste("Best K-Means Attempt out of 100\n WCV: ",
round(km.faithfulsim$tot.withinss, 4)))
###########################################
#####Tools for Hierarchical Clustering#####
###########################################
library(flexclust) #Loading the flexclust library.
data(nutrient) #Loading the nutrient data.
help(nutrient) #Inspecting the data set; nutrients in meat, fish, and fowel.
nutrient
#Notice that the nutrient columns are in different measurements: calories,
#grams, and milligrams.
summary(nutrient)
sapply(nutrient, sd)
#We should scale the data.
nutrient.scaled = as.data.frame(scale(nutrient))
###########################################
#####Tools for Hierarchical Clustering#####
###########################################
library(flexclust) #Loading the flexclust library.
###########################################
#####Tools for Hierarchical Clustering#####
###########################################
install.packages('flexclust')
library(flexclust) #Loading the flexclust library.
library(flexclust) #Loading the flexclust library.
data(nutrient) #Loading the nutrient data.
help(nutrient) #Inspecting the data set; nutrients in meat, fish, and fowel.
nutrient
#Notice that the nutrient columns are in different measurements: calories,
#grams, and milligrams.
summary(nutrient)
sapply(nutrient, sd)
#We should scale the data.
nutrient.scaled = as.data.frame(scale(nutrient))
summary(nutrient.scaled)
sapply(nutrient.scaled, sd)
#We need to calcualte the pairwise distances between observations.
d = dist(nutrient.scaled)
#Using the hclust() function, we define the linkage manner by which we will
#cluster our data.
fit.single = hclust(d, method = "single")
fit.complete = hclust(d, method = "complete")
fit.average = hclust(d, method = "average")
#Creating various dendrograms.
par(mfrow = c(1, 3))
plot(fit.single, hang = -1, main = "Dendrogram of Single Linkage")
plot(fit.complete, hang = -1, main = "Dendrogram of Complete Linkage")
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage")
nutrient
help(nutrient) #Inspecting the data set; nutrients in meat, fish, and fowel.
library(flexclust) #Loading the flexclust library.
data(nutrient) #Loading the nutrient data.
help(nutrient) #Inspecting the data set; nutrients in meat, fish, and fowel.
nutrient
#Notice that the nutrient columns are in different measurements: calories,
#grams, and milligrams.
summary(nutrient)
sapply(nutrient, sd)
#We should scale the data.
nutrient.scaled = as.data.frame(scale(nutrient))
summary(nutrient.scaled)
sapply(nutrient.scaled, sd)
#We need to calcualte the pairwise distances between observations.
d = dist(nutrient.scaled)
#Using the hclust() function, we define the linkage manner by which we will
#cluster our data.
fit.single = hclust(d, method = "single")
fit.complete = hclust(d, method = "complete")
fit.average = hclust(d, method = "average")
#Creating various dendrograms.
par(mfrow = c(1, 3))
plot(fit.single, hang = -1, main = "Dendrogram of Single Linkage")
plot(fit.single, hang = -1, main = "Dendrogram of Single Linkage")
plot(fit.complete, hang = -1, main = "Dendrogram of Complete Linkage")
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage")
#Cut the dendrogram into groups of data.
clusters.average = cutree(fit.average, k = 5)
clusters.average
library(flexclust) #Loading the flexclust library.
data(nutrient) #Loading the nutrient data.
help(nutrient) #Inspecting the data set; nutrients in meat, fish, and fowel.
nutrient
#Notice that the nutrient columns are in different measurements: calories,
#grams, and milligrams.
summary(nutrient)
sapply(nutrient, sd)
#We should scale the data.
nutrient.scaled = as.data.frame(scale(nutrient))
summary(nutrient.scaled)
sapply(nutrient.scaled, sd)
#We need to calcualte the pairwise distances between observations.
d = dist(nutrient.scaled)
#Using the hclust() function, we define the linkage manner by which we will
#cluster our data.
fit.single = hclust(d, method = "single")
fit.complete = hclust(d, method = "complete")
fit.average = hclust(d, method = "average")
#Cut the dendrogram into groups of data.
clusters.average = cutree(fit.average, k = 5)
clusters.average
clusters.average
#Viewing the groups of data.
table(clusters.average)
#Aggregating the original data by the cluster assignments.
aggregate(nutrient, by = list(cluster = clusters.average), median)
#Aggregating the scaled data by the cluster assignments.
aggregate(nutrient.scaled, by = list(cluster = clusters.average), median)
#Visualizing the groups in the dendrogram.
par(mfrow = c(1, 1))
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage\n5 Clusters")
rect.hclust(fit.average, k = 5)
plot(fit.average, hang = 1, main = "Dendrogram of Average Linkage\n5 Clusters")
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage\n5 Clusters")
plot(fit.average, hang = 1, main = "Dendrogram of Average Linkage\n5 Clusters")
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage\n5 Clusters")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
Library(ISLR)
Library('ISLR')
library('ISLR')
load(OJ)
load(OJ)
load(OJ.csv)
load(OJ)
attach(OJ)
data(OJ)
head(OJ)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(ISLR)
head(OJ)
# construct initial tree
library(tree)
initial.tree = tree(Purchase ~ ., split = "gini", data = OJ.train)
# training accuracy
summary(initial.tree)
# train/test split
set.seed(0)
train = sample(1:nrow(OJ), 8*nrow(OJ)/10)
OJ.train = OJ[train, ]
head(OJ)
set.seed(0)
OJ.train = OJ[train, ]
OJ.test = OJ [train, ]
# construct initial tree
library(tree)
initial.tree = tree(Purchase ~ ., split = "gini", data = OJ.train)
# training accuracy
summary(initial.tree)
# testing accuracy
tree.predictions = predict(initial.tree, OJ.test, type = "class")
table(tree.predictions, OJ.test$Purchase)
(106 + 59)/nrow(OJ.test)
# training accuracy
summary(initial.tree)
# testing accuracy
tree.predictions = predict(initial.tree, OJ.test, type = "class")
table(tree.predictions, OJ.test$Purchase)
(106 + 59)/nrow(OJ.test)
# construct initial tree
library(tree)
initial.tree = tree(Purchase ~ ., split = "gini", data = OJ.train)
# training accuracy
summary(initial.tree)
# testing accuracy
tree.predictions = predict(initial.tree, OJ.test, type = "class")
set.seed(0)
cv.training = cv.tree(initial.tree, FUN = prune.misclass)
set.seed(0)
cv.training = cv.tree(initial.tree, FUN = prune.misclass)
set.seed(0)
cv.training = cv.tree(initial.tree, FUN = prune.misclass)
par(mfrow = c(1, 2))
plot(cv.training$size, cv.training$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
plot(cv.training$k, cv.training$dev, type  = "b",
xlab = "Alpha", ylab = "Misclassified Observations")
par(mfrow = c(1, 2))
plot(cv.training$size, cv.training$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
plot(cv.training$k, cv.training$dev, type  = "b",
xlab = "Alpha", ylab = "Misclassified Observations")
plot(cv.training$size, cv.training$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
# prune initial tree with cv results
best.nodes = cv.training$size[which(cv.training$dev == min(cv.training$dev))] # optimal number of nodes is 11
prune.tree = prune.misclass(initial.tree, best = best.nodes)
# training accuracy
summary(prune.tree)  # the accuracy of the pruned tree is approximately 80%
# testing accuracy
prune.predictions = predict(prune.tree, OJ.test, type = "class")
par(mfrow = c(1, 1))
par(mfrow = c(1, 1))
plot(prune.tree)
# prune initial tree with cv results
best.nodes = cv.training$size[which(cv.training$dev == min(cv.training$dev))] # optimal number of nodes is 11
# training accuracy
summary(prune.tree)  # the accuracy of the pruned tree is approximately 80%
# testing accuracy
prune.predictions = predict(prune.tree, OJ.test, type = "class")
table(prune.predictions, OJ.test$Purchase)
(113 + 57)/nrow(OJ.test)
# visualize pruned tree
prune.tree
par(mfrow = c(1, 1))
plot(prune.tree)
text(prune.tree)
# prediction accuracy pruned tree vs. initial tree
#The initial tree is likely overfitting to our data, even though it stops splitting
#before placing each observation into its own terminal node. The cost-complexity
#pruning process provides a balance that will ultimately produce a model that
#penalizes complexity to a certain degree in order to stray from the potential
#of overfitting.
# grow the forest
library(randomForest)
set.seed(0)
rf.default = randomForest(Purchase ~., data = OJ.train, importance = TRUE)
rf.default = randomForest(Purchase ~., data = OJ.train, importance = TRUE)
# training and testing accuracies
rf.default
table(predict(rf.default, OJ.test, type = "class"), OJ.test$Purchase)
(113 + 60)/nrow(OJ.test)
# top variable
importance(rf.default)
varImpPlot(rf.default)
# training and testing accuracies
rf.default
# prune initial tree with cv results
best.nodes = cv.training$size[which(cv.training$dev == min(cv.training$dev))] # optimal number of nodes is 11
prune.tree = prune.misclass(initial.tree, best = best.nodes)
# training accuracy
summary(prune.tree)  # the accuracy of the pruned tree is approximately 80%
# testing accuracy
prune.predictions = predict(prune.tree, OJ.test, type = "class")
table(prune.predictions, OJ.test$Purchase)
(113 + 57)/nrow(OJ.test)
# visualize pruned tree
prune.tree
par(mfrow = c(1, 1))
plot(prune.tree)
text(prune.tree)
plot(prune.tree)
text(prune.tree)
# prune initial tree with cv results
best.nodes = cv.training$size[which(cv.training$dev == min(cv.training$dev))] # optimal number of nodes is 11
prune.tree = prune.misclass(initial.tree, best = best.nodes)
# training accuracy
summary(prune.tree)  # the accuracy of the pruned tree is approximately 80%
# testing accuracy
prune.predictions = predict(prune.tree, OJ.test, type = "class")
table(prune.predictions, OJ.test$Purchase)
(113 + 57)/nrow(OJ.test)
# visualize pruned tree
prune.tree
par(mfrow = c(1, 1))
plot(prune.tree)
text(prune.tree)
# grow the forest
library(randomForest)
set.seed(0)
rf.default = randomForest(Purchase ~., data = OJ.train, importance = TRUE)
# training and testing accuracies
rf.default
table(predict(rf.default, OJ.test, type = "class"), OJ.test$Purchase)
(113 + 60)/nrow(OJ.test)
# top variable
importance(rf.default)
varImpPlot(rf.default)
set.seed(0)
oob.err = numeric(17)
for (mtry in 1:17) {
fit = randomForest(Purchase ~ ., data = OJ.train, mtry = mtry)
oob.err[mtry] = fit$err.rate[500, 1]
cat("We're performing iteration", mtry, "\n")
}
set.seed(0)
oob.err = numeric(17)
for (mtry in 1:17) {
fit = randomForest(Purchase ~ ., data = OJ.train, mtry = mtry)
oob.err[mtry] = fit$err.rate[500, 1]
cat("We're performing iteration", mtry, "\n")
}
#mtry: Number of variables randomly sampled as candidates at each split.
#Since by default, ntree=500
# visualize oob error rates
plot(1:17, oob.err, pch = 16, type = "b",
xlab = "Variables Considered at Each Split",
ylab = "OOB Misclassification Rate",
main = "Random Forest OOB Error Rates\nby # of Variables")
# maximum acuracy and optimal variables
1 - min(oob.err)
which(oob.err == min(oob.err))
#The maximum accuracy among our random forests on the training set is approximately
#81.08%, corresponding to the random forest that considered only 2 variables at each split.
# bagged model accuracy
1 - oob.err[17]
#The accuracy of the bagged model (m = p) on the training set is approximately 80.02%,
#corresponding to the random forest that considered each of the 17 variables at
#each split.
set.seed(0)
rf.2var = randomForest(Purchase ~ ., data = OJ.train, mtry = 2)
table(predict(rf.2var, OJ.test, type = "class"), OJ.test$Purchase)
(118 + 58)/nrow(OJ.test)
#The accuracy of the random forest that only consideres 2 variables at each node
#split on the test set is approximately 82.24%.
set.seed(0)
rf.bagged = randomForest(Purchase ~ ., data = OJ.train, mtry = 17)
table(predict(rf.bagged, OJ.test, type = "class"), OJ.test$Purchase)
(110 + 62)/nrow(OJ.test)
#The accuracy of the bagged model on the test set is approximately 80.38%.
# To see if selecting with lasso is better, first we split the data
# into training and test part. The we run the two processes (with
# and without lasso) on the training set, and evaluate the final part
# on the test set. Since the result actually depends on the splitting,
# here we actually splt multiple times to see that the result with
# is slightly better. Though we need to still bare in mind that this
# result is still subject to this particular dataset.
library(glmnet)
test_lasso_rf <- function(k){
## train-test splitting
set.seed(k)
train = sample(1:nrow(OJ), 8*nrow(OJ)/10)
## Random forest alone
OJ.train = OJ[train,]
OJ.test = OJ[-train,]
oob.err = numeric(17)
for (mtry in 1:17) {
fit = randomForest(Purchase ~ ., data = OJ.train, mtry = mtry)
oob.err[mtry] = fit$err.rate[500, 1]
}
rf = randomForest(Purchase ~ ., data = OJ.train,
mtry = which(oob.err == min(oob.err)))
confusion = table(predict(rf, OJ.test, type = "class"), OJ.test$Purchase)
rf.accuracy = (confusion[1,1]+confusion[2,2])/nrow(OJ.test)
## Feature selection before random forest
x = model.matrix(Purchase ~ ., OJ)[,-1]
y = (OJ$Purchase == 'MM')
X_train = x[train, ]
y_train = y[train]
X_test = x[-train, ]
y_test = y[-train]
grid = 10^seq(3, -5, length = 100)
cv.lasso.out = cv.glmnet(X_train, y_train,
lambda = grid, alpha = 1, nfolds = 10)
cv.lasso.out$lambda.min
coef_ = predict(cv.lasso.out, s = cv.lasso.out$lambda.min,
type = "coefficients")
lasso_select = coef_@Dimnames[[1]][coef_@i +1][-1]
OJ.train = as.data.frame(x)[train, lasso_select]
OJ.test = as.data.frame(x)[-train, lasso_select]
OJ.train$Purchase = OJ[train, "Purchase"]
OJ.test$Purchase = OJ[-train, "Purchase"]
set.seed(0)
n = length(lasso_select)
oob.err = numeric(n)
for (mtry in 1:n) {
fit = randomForest(Purchase ~ ., data = OJ.train, mtry = mtry)
oob.err[mtry] = fit$err.rate[500, 1]
}
rf.lasso = randomForest(Purchase ~ ., data = OJ.train,
mtry = which(oob.err == min(oob.err)))
confusion = table(predict(rf.lasso, OJ.test, type = "class"), OJ.test$Purchase)
rf.lasso.accuracy = (confusion[1,1]+confusion[2,2])/nrow(OJ.test)
return(rf.lasso.accuracy - rf.accuracy)
}
result = numeric()
for(i in 1:10){
print(i)
result[i] = test_lasso_rf(i)
}
OJ.train.indicator = OJ.train
OJ.test.indicator = OJ.test
OJ.train.indicator$Purchase = as.vector(OJ.train$Purchase, mode = "numeric") - 1
OJ.test.indicator$Purchase = as.vector(OJ.test$Purchase, mode = "numeric") - 1
library(gbm)
set.seed(0)
boost.initial = gbm(Purchase ~ ., data = OJ.train.indicator,
distribution = "bernoulli",
n.trees = 10000,
interaction.depth = 4,
shrinkage = 0.001)
n.trees = seq(from = 100, to = 10000, by = 100)
boost.predictions = predict(boost.initial,
newdata = OJ.test.indicator,
n.trees = n.trees,
type = "response")
boost.predictions = round(boost.predictions)
accuracy.boost = numeric(100)
for (i in 1:100) {
accuracy.boost[i] = sum(diag(table(OJ.test.indicator$Purchase, boost.predictions[, i]))) / 214
}
min(which(accuracy.boost == max(accuracy.boost)) * 100)
#In this setting, we would ultimately choose a boosted model that has 2,100 trees.
#-----------------------------------------Another way to do it-------------------------------------------#
acc=rep(0,100)
for (i in 1:100){
acc[i]<-length(which(boost.predictions [,i]==OJ.test.indicator$Purchase))/length(OJ.test.indicator$Purchase)
}
max(acc)
#[1] 0.8364485981
which.max(acc)
# [1] 21 -- so num. of tree = 2,100
plot(n.trees, accuracy.boost, pch = 16, type = "b",
xlab = "Number of Trees",
ylab = "Accuracy",
main = "Accuracy of Boosted Trees")
abline(h = max(accuracy.boost), lty = 2) #Boosting.
abline(h = (1 - min(oob.err)), col = "red3", lty = 2) #Random forests.
abline(h = (113 + 57)/nrow(OJ.test), col = "blue", lty = 2) #Pruned tree.
legend("bottomright",
c("Boosting", "Random Forests", "Pruned Tree"),
lwd = 2,
lty = 2,
col = c("black", "red3", "blue"))
library(shiny)
library(dplyr)
library(ggplot2)
library(DT)
library(leaflet)
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
##MEDIUM DATASET##
#loading medium dataset
medium = read.csv(file = "mediumfinal.csv")
setwd("C:/Users/adlar/Desktop/webscrape_inshiny")
medium
##MEDIUM DATASET##
#loading medium dataset
medium = read.csv(file = "mediumfinal.csv")
medium
medium
setwd("C:/Users/adlar/Desktop/webscrape_inshiny")
medium
head(medium)
#removing nonclean date column
medium$Date = NULL
head(medium)
#renaming of date.fixed column
colnames(medium)[colnames(medium)=="Date.Fixed"] = "Date"
head(medium)
View(medium)
##COMBINED MEDIUM AND TAGS##
#combine of tags and medium dataset
combined = cbind(medium, tags)
head(combined)
head(combined)
